{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import re\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_contents = open(r'E:\\Mat_Work\\machine-learning-ex6\\ex6\\emailSample1.txt','r').read()\n",
    "vocabList = open(r'E:\\Mat_Work\\machine-learning-ex6\\ex6\\vocab.txt','r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabList = vocabList.split('\\n')[:-1]\n",
    "vocabList_d = {}\n",
    "i = 0\n",
    "for ea in vocabList:\n",
    "    value,key = ea.split('\\t')[:]\n",
    "    vocabList_d[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processEmail(email_contents,vocabList_d):\n",
    "    \"\"\"\n",
    "    Preprocesses the body of an email and returns a list of indices of the words contained in the email. \n",
    "    \"\"\"\n",
    "    # Lower case\n",
    "    email_contents = email_contents.lower()\n",
    "    \n",
    "    # Handle numbers\n",
    "    email_contents = re.sub(\"[0-9]+\",\"number\",email_contents)\n",
    "    \n",
    "    # Handle URLS\n",
    "    email_contents = re.sub(\"[http|https]://[^\\s]*\",\"httpaddr\",email_contents)\n",
    "    \n",
    "    # Handle Email Addresses\n",
    "    email_contents = re.sub(\"[^\\s]+@[^\\s]+\",\"emailaddr\",email_contents)\n",
    "    \n",
    "    # Handle $ sign\n",
    "    email_contents = re.sub(\"[$]+\",\"dollar\",email_contents)\n",
    "    \n",
    "    # Strip all special characters\n",
    "    specialChar = [\"<\",\"[\",\"^\",\">\",\"+\",\"?\",\"!\",\"'\",\".\",\",\",\":\"]\n",
    "    for char in specialChar:\n",
    "        email_contents = email_contents.replace(char,\"\")\n",
    "    email_contents = email_contents.replace(\"\\n\",\" \")    \n",
    "    \n",
    "    # Stem the word\n",
    "    ps = PorterStemmer()\n",
    "    email_contents = [ps.stem(token) for token in email_contents.split(\" \")]\n",
    "    email_contents= \" \".join(email_contents)\n",
    "    \n",
    "    # Process the email and return word_indices\n",
    "    \n",
    "    word_indices=[]\n",
    "    \n",
    "    for char in email_contents.split():\n",
    "        if len(char) >1 and char in vocabList_d:\n",
    "            word_indices.append(int(vocabList_d[char]))\n",
    "    \n",
    "    return word_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_indices= processEmail(file_contents,vocabList_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emailFeatures(word_indices,vocabList_d):\n",
    "    n = len(vocabList_d)\n",
    "    features = np.zeros((n,1))\n",
    "    for i in word_indices:\n",
    "        features[i] = 1\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of feature vector:  1899\n",
      "Number of non-zero entries:  43.0\n"
     ]
    }
   ],
   "source": [
    "features = emailFeatures(word_indices,vocabList_d)\n",
    "print(\"Length of feature vector: \",len(features))\n",
    "print(\"Number of non-zero entries: \",np.sum(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_mat = loadmat('E:\\Mat_Work\\machine-learning-ex6\\ex6\\spamTrain.mat')\n",
    "X_train = spam_mat['X']\n",
    "y_train = spam_mat['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 99.825 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "C = 0.1\n",
    "spam_classifier = SVC(C=C,kernel='linear')\n",
    "spam_classifier.fit(X_train,y_train.ravel())\n",
    "print('Training accuracy:',(spam_classifier.score(X_train,y_train.ravel()))*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.9 %\n"
     ]
    }
   ],
   "source": [
    "spam_mat_test = loadmat('E:\\Mat_Work\\machine-learning-ex6\\ex6\\spamTest.mat')\n",
    "X_test = spam_mat_test['Xtest']\n",
    "y_test = spam_mat_test['ytest']\n",
    "spam_classifier.predict(X_test)\n",
    "print(\"Test Accuracy:\",(spam_classifier.score(X_test,y_test.ravel()))*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top predictors of spam:\n",
      "our \t\t 0.500614\n",
      "click \t\t 0.465916\n",
      "remov \t\t 0.422869\n",
      "guarante \t\t 0.383622\n",
      "visit \t\t 0.36771\n",
      "basenumb \t\t 0.345064\n",
      "dollar \t\t 0.323632\n",
      "will \t\t 0.269724\n",
      "price \t\t 0.267298\n",
      "pleas \t\t 0.261169\n",
      "most \t\t 0.257298\n",
      "nbsp \t\t 0.253941\n",
      "lo \t\t 0.253467\n",
      "ga \t\t 0.248297\n",
      "hour \t\t 0.246404\n"
     ]
    }
   ],
   "source": [
    "weights = spam_classifier.coef_[0]\n",
    "weights_col = np.hstack((np.arange(1,1900).reshape(1899,1),weights.reshape(1899,1)))\n",
    "df = pd.DataFrame(weights_col)\n",
    "df.sort_values(by=[1],ascending=False,inplace=True)\n",
    "predictors = []\n",
    "idx = []\n",
    "for i in df[0][:15]:\n",
    "    for keys, values in vocabList_d.items():\n",
    "        if str(int(i)) == values:\n",
    "            predictors.append(keys)\n",
    "            idx.append(int(values))\n",
    "print(\"Top predictors of spam:\")\n",
    "for _ in range(15):\n",
    "    print(predictors[_],\"\\t\\t\",round(df[1][idx[_]-1],6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
